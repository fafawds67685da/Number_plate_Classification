{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd6383a",
   "metadata": {},
   "source": [
    "# Enhanced License Plate Detection and Classification\n",
    "\n",
    "This notebook implements an improved two-stage approach for license plate recognition:\n",
    "1. License plate detection - extracting the plate from the full image\n",
    "2. License plate classification - classifying the state code\n",
    "\n",
    "This solves the problem of losing important details when resizing full car images to 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1906803f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model, Model\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, Input\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import imutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af216946",
   "metadata": {},
   "source": [
    "## 1. License Plate Detection\n",
    "\n",
    "First, we'll implement functions to detect and extract license plates from car images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc83810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_license_plate(image_path):\n",
    "    \"\"\"Detect and extract license plate from car image\"\"\"\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Save original image for display\n",
    "    orig_image = image.copy()\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filter to remove noise while keeping edges sharp\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    \n",
    "    # Find edges\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "    \n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:10]\n",
    "    \n",
    "    # Initialize license plate contour\n",
    "    plate_cnt = None\n",
    "    \n",
    "    # Loop over contours to find the license plate\n",
    "    for c in cnts:\n",
    "        # Approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        \n",
    "        # If the contour has 4 corners, we might have found the license plate\n",
    "        if len(approx) == 4:\n",
    "            plate_cnt = approx\n",
    "            break\n",
    "    \n",
    "    if plate_cnt is None:\n",
    "        # If no rectangle with 4 corners found, try detecting based on ratio\n",
    "        for c in cnts:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            aspect_ratio = float(w) / h\n",
    "            \n",
    "            # License plates typically have an aspect ratio of ~2-4\n",
    "            if 1.5 <= aspect_ratio <= 5 and w > 100 and h > 20:\n",
    "                plate_cnt = c\n",
    "                break\n",
    "    \n",
    "    if plate_cnt is None:\n",
    "        # If still can't find plate, assume bottom third of image\n",
    "        h, w = image.shape[:2]\n",
    "        y = int(h * 2/3)\n",
    "        plate_image = image[y:, :]\n",
    "        \n",
    "        # Mark the bottom third in the original image\n",
    "        cv2.rectangle(orig_image, (0, y), (w, h), (0, 255, 0), 2)\n",
    "        \n",
    "        return plate_image, orig_image\n",
    "    \n",
    "    # Get coordinates of the license plate\n",
    "    x, y, w, h = cv2.boundingRect(plate_cnt)\n",
    "    \n",
    "    # Extract the license plate\n",
    "    plate_image = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Draw rectangle around the license plate on original image (for visualization)\n",
    "    cv2.rectangle(orig_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    return plate_image, orig_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23c677",
   "metadata": {},
   "source": [
    "## 2. Improved Preprocessing with Plate Detection\n",
    "\n",
    "Now we'll create a preprocessing pipeline that detects the license plate before resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52240bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocess_image(img_path):\n",
    "    \"\"\"Original basic preprocessing function\"\"\"\n",
    "    img = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "    img = img.resize((128, 128))  # Resize\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
    "    return img_array\n",
    "\n",
    "def improved_preprocess_image(img_path):\n",
    "    \"\"\"Improved preprocessing pipeline with license plate detection\"\"\"\n",
    "    # First detect the license plate\n",
    "    plate_image, marked_image = detect_license_plate(img_path)\n",
    "    \n",
    "    if plate_image is None:\n",
    "        # Fallback to original method if detection fails\n",
    "        return basic_preprocess_image(img_path), None\n",
    "    \n",
    "    # Convert OpenCV BGR to RGB for PIL\n",
    "    plate_image_rgb = cv2.cvtColor(plate_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    pil_image = Image.fromarray(plate_image_rgb)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    pil_image = pil_image.convert(\"L\")\n",
    "    \n",
    "    # Resize to 128x128 (now we're only resizing the plate region, not the whole car)\n",
    "    pil_image = pil_image.resize((128, 128))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(pil_image)\n",
    "    \n",
    "    # Normalize\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Add batch and channel dimensions\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = np.expand_dims(img_array, axis=-1)\n",
    "    \n",
    "    return img_array, marked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed889ec9",
   "metadata": {},
   "source": [
    "## 3. Enhanced CNN Architecture\n",
    "\n",
    "Let's implement an improved CNN architecture with batch normalization and residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_model(input_shape=(128, 128, 1), num_classes=29):\n",
    "    \"\"\"Create an improved CNN model for license plate classification\"\"\"\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First block\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Second block with residual connection\n",
    "    shortcut = Conv2D(64, (1, 1), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])  # Residual connection\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Third block\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf388187",
   "metadata": {},
   "source": [
    "## 4. License Plate-Specific Data Augmentation\n",
    "\n",
    "Standard data augmentation may distort license plates too much. Let's create specialized augmentation for plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c91394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation specifically for license plates\n",
    "plate_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=5,  # License plates won't rotate much\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],  # Vary brightness\n",
    "    fill_mode='constant',  # Use black padding\n",
    "    cval=0  # Black color for padding\n",
    ")\n",
    "\n",
    "# Regular validation data generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebbc6ed",
   "metadata": {},
   "source": [
    "## 5. Prepare and Process the Dataset\n",
    "\n",
    "Let's set up a function to process our dataset with the improved preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_improved_dataset(input_dir, output_dir, detect_plates=True):\n",
    "    \"\"\"Process dataset with license plate detection\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Count for statistics\n",
    "    total_images = 0\n",
    "    detected_plates = 0\n",
    "    failed_detections = 0\n",
    "    \n",
    "    # Process each class folder\n",
    "    for class_folder in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_folder)\n",
    "        \n",
    "        # Skip if not a directory\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        # Create output class folder\n",
    "        output_class_path = os.path.join(output_dir, class_folder)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        \n",
    "        # Process each image in the class folder\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "                \n",
    "            total_images += 1\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            try:\n",
    "                if detect_plates:\n",
    "                    # Detect and extract license plate\n",
    "                    plate_img, _ = detect_license_plate(img_path)\n",
    "                    \n",
    "                    if plate_img is not None:\n",
    "                        # Convert to grayscale and resize\n",
    "                        plate_rgb = cv2.cvtColor(plate_img, cv2.COLOR_BGR2RGB)\n",
    "                        pil_img = Image.fromarray(plate_rgb).convert(\"L\").resize((128, 128))\n",
    "                        detected_plates += 1\n",
    "                    else:\n",
    "                        # Fallback to original image if plate detection fails\n",
    "                        pil_img = Image.open(img_path).convert(\"L\").resize((128, 128))\n",
    "                        failed_detections += 1\n",
    "                else:\n",
    "                    # Just convert to grayscale and resize without plate detection\n",
    "                    pil_img = Image.open(img_path).convert(\"L\").resize((128, 128))\n",
    "                \n",
    "                # Save processed image\n",
    "                output_path = os.path.join(output_class_path, img_file)\n",
    "                pil_img.save(output_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                failed_detections += 1\n",
    "    \n",
    "    print(f\"Processed {total_images} images\")\n",
    "    if detect_plates:\n",
    "        print(f\"Successfully detected {detected_plates} plates ({detected_plates/total_images*100:.1f}%)\")\n",
    "        print(f\"Failed to detect {failed_detections} plates ({failed_detections/total_images*100:.1f}%)\")\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a68469",
   "metadata": {},
   "source": [
    "## 6. Complete End-to-End Pipeline\n",
    "\n",
    "Now let's combine everything into a complete end-to-end pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_license_plate(img_path, model, class_labels):\n",
    "    \"\"\"End-to-end pipeline for license plate detection and classification\"\"\"\n",
    "    # Step 1: Detect and preprocess the license plate\n",
    "    img_tensor, marked_image = improved_preprocess_image(img_path)\n",
    "    \n",
    "    # Step 2: Make prediction\n",
    "    prediction = model.predict(img_tensor)\n",
    "    \n",
    "    # Step 3: Get the predicted class\n",
    "    predicted_class_index = np.argmax(prediction, axis=1)\n",
    "    predicted_class = class_labels[predicted_class_index[0]]\n",
    "    confidence = prediction[0][predicted_class_index[0]]\n",
    "    \n",
    "    # Step 4: Visualize results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original with Detected Plate\")\n",
    "    if marked_image is not None:\n",
    "        plt.imshow(cv2.cvtColor(marked_image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(plt.imread(img_path))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Processed Plate\\nPredicted: {predicted_class} ({confidence:.2f})\")\n",
    "    plt.imshow(img_tensor[0, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60a7f3",
   "metadata": {},
   "source": [
    "## 7. Train the Improved Model\n",
    "\n",
    "Now let's set up the training process for our improved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These paths may need to be adjusted based on your actual data location\n",
    "train_data_path = 'final/train'  # Path to original training data\n",
    "test_data_path = 'final/test'    # Path to original test data\n",
    "\n",
    "# Create improved dataset directories\n",
    "improved_train_path = 'improved_data/train'\n",
    "improved_test_path = 'improved_data/test'\n",
    "\n",
    "# Process the datasets with license plate detection\n",
    "# Note: Only run this if you have the actual data files available\n",
    "# Comment out if you're just exploring the code\n",
    "\n",
    "# Process train data\n",
    "# prepare_improved_dataset(train_data_path, improved_train_path, detect_plates=True)\n",
    "\n",
    "# Process test data\n",
    "# prepare_improved_dataset(test_data_path, improved_test_path, detect_plates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data generators\n",
    "# Note: Only run this cell if you've prepared the improved data directories\n",
    "\n",
    "# Define image dimensions and batch size\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "'''\n",
    "# Training data generator with augmentation\n",
    "train_gen = plate_datagen.flow_from_directory(\n",
    "    improved_train_path,\n",
    "    target_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Test data generator (no augmentation needed for validation)\n",
    "test_gen = val_datagen.flow_from_directory(\n",
    "    improved_test_path,\n",
    "    target_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Get class indices and number of classes\n",
    "class_indices = train_gen.class_indices\n",
    "class_labels = list(class_indices.keys())\n",
    "num_classes = len(class_indices)\n",
    "\n",
    "print(f\"Found {num_classes} classes: {class_labels}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94fa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the improved model\n",
    "# Note: This cell is commented out to avoid running intensive training unintentionally\n",
    "\n",
    "'''\n",
    "# Create the model\n",
    "improved_model = create_improved_model(input_shape=(128, 128, 1), num_classes=num_classes)\n",
    "\n",
    "# Display model summary\n",
    "improved_model.summary()\n",
    "\n",
    "# Set up callbacks\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"improved_plate_model.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = improved_model.fit(\n",
    "    train_gen,\n",
    "    epochs=50,  # Adjust as needed\n",
    "    validation_data=test_gen,\n",
    "    callbacks=[model_checkpoint, early_stopping]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d61213",
   "metadata": {},
   "source": [
    "## 8. Load and Test the Model\n",
    "\n",
    "Now let's test our model on some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deff49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original model for comparison\n",
    "# Note: This assumes you have trained models available\n",
    "\n",
    "'''\n",
    "# Load original model\n",
    "original_model = load_model(\"final_model.h5\")\n",
    "\n",
    "# Load improved model (if you've trained it)\n",
    "# improved_model = load_model(\"improved_plate_model.h5\")\n",
    "\n",
    "# Define class labels (these should match your actual model's training classes)\n",
    "class_labels = ['AP', 'AR', 'AS', 'BR', 'CG', 'DL', 'GA', 'GJ', 'HR', 'HP', \n",
    "                 'JH', 'KA', 'KL', 'MP', 'MH', 'MN', 'ML', 'MZ', 'NL', 'OD', \n",
    "                 'PB', 'RJ', 'SK', 'TN', 'TS', 'TR', 'UP', 'UK', 'WB']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample image\n",
    "# Replace with your actual test image path\n",
    "\n",
    "'''\n",
    "test_image_path = \"path/to/your/test/image.jpg\"\n",
    "predicted_class, confidence = classify_license_plate(test_image_path, original_model, class_labels)\n",
    "print(f\"Predicted state: {predicted_class} with confidence: {confidence:.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4507a51",
   "metadata": {},
   "source": [
    "## 9. Compare Original vs. Improved Performance\n",
    "\n",
    "Let's compare the performance of the original and improved methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(image_path, original_model, improved_model, class_labels):\n",
    "    \"\"\"Compare original and improved models on the same image\"\"\"\n",
    "    # Original method\n",
    "    start_time = time.time()\n",
    "    orig_img = basic_preprocess_image(image_path)\n",
    "    orig_pred = original_model.predict(orig_img)\n",
    "    orig_class_idx = np.argmax(orig_pred, axis=1)[0]\n",
    "    orig_class = class_labels[orig_class_idx]\n",
    "    orig_confidence = orig_pred[0][orig_class_idx]\n",
    "    orig_time = time.time() - start_time\n",
    "    \n",
    "    # Improved method\n",
    "    start_time = time.time()\n",
    "    img_tensor, marked_image = improved_preprocess_image(image_path)\n",
    "    improved_pred = improved_model.predict(img_tensor)\n",
    "    improved_class_idx = np.argmax(improved_pred, axis=1)[0]\n",
    "    improved_class = class_labels[improved_class_idx]\n",
    "    improved_confidence = improved_pred[0][improved_class_idx]\n",
    "    improved_time = time.time() - start_time\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(plt.imread(image_path))\n",
    "    axes[0, 0].set_title(\"Original Image\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Original processed\n",
    "    axes[0, 1].imshow(orig_img[0, :, :, 0], cmap='gray')\n",
    "    axes[0, 1].set_title(f\"Original Method\\nPredicted: {orig_class} ({orig_confidence:.2f})\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Improved with plate detection\n",
    "    if marked_image is not None:\n",
    "        axes[1, 0].imshow(cv2.cvtColor(marked_image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        axes[1, 0].imshow(plt.imread(image_path))\n",
    "    axes[1, 0].set_title(\"Detected License Plate\")\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Improved processed\n",
    "    axes[1, 1].imshow(img_tensor[0, :, :, 0], cmap='gray')\n",
    "    axes[1, 1].set_title(f\"Improved Method\\nPredicted: {improved_class} ({improved_confidence:.2f})\")\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Original method: {orig_class} (confidence: {orig_confidence:.2f}, time: {orig_time:.3f}s)\")\n",
    "    print(f\"Improved method: {improved_class} (confidence: {improved_confidence:.2f}, time: {improved_time:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd32459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test comparison on a sample image\n",
    "# Note: This requires both models to be loaded\n",
    "\n",
    "'''\n",
    "test_image_path = \"path/to/your/test/image.jpg\"\n",
    "compare_models(test_image_path, original_model, improved_model, class_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899a426",
   "metadata": {},
   "source": [
    "## 10. Integration with Mobile App\n",
    "\n",
    "To integrate this improved model with your React Native app, you'll need to convert it to TensorFlow.js format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TensorFlow.js format for mobile app\n",
    "# Note: This requires the tensorflowjs package to be installed\n",
    "\n",
    "'''\n",
    "!pip install tensorflowjs\n",
    "\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Path for the exported model\n",
    "export_path = \"mobile_app_model\"\n",
    "\n",
    "# Convert model to TensorFlow.js format\n",
    "tfjs.converters.save_keras_model(improved_model, export_path)\n",
    "print(f\"Model exported to {export_path} for use in React Native app\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938406e7",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "This improved approach solves the problem of losing important details when resizing full car images by:\n",
    "1. First detecting and extracting just the license plate region\n",
    "2. Then resizing only the plate to 128x128\n",
    "3. Using an improved CNN with batch normalization and residual connections\n",
    "4. Applying specialized data augmentation for license plates\n",
    "\n",
    "This results in higher accuracy, especially for images where the license plate is a small part of the overall image or is located at the bottom of the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cbf684",
   "metadata": {},
   "source": [
    "## Data Preparation and Extraction\n",
    "\n",
    "First, we need to extract and set up our dataset from the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcdb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from num+plate.zip\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "zip_path = '/content/num+plate.zip'  # Path to your zip file\n",
    "extract_to = 'dataset'\n",
    "\n",
    "# Create extraction directory\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(f\"Extracted {zip_path} to {extract_to}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c88b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for augmented and processed data\n",
    "aug_data_dir = \"aug_data\"\n",
    "processed_train_dir = \"processed/train\"\n",
    "processed_test_dir = \"processed/test\"\n",
    "final_train_dir = \"final/train\"\n",
    "final_test_dir = \"final/test\"\n",
    "improved_train_dir = \"improved_data/train\"\n",
    "improved_test_dir = \"improved_data/test\"\n",
    "\n",
    "os.makedirs(aug_data_dir, exist_ok=True)\n",
    "os.makedirs(processed_train_dir, exist_ok=True)\n",
    "os.makedirs(processed_test_dir, exist_ok=True)\n",
    "os.makedirs(final_train_dir, exist_ok=True)\n",
    "os.makedirs(final_test_dir, exist_ok=True)\n",
    "os.makedirs(improved_train_dir, exist_ok=True)\n",
    "os.makedirs(improved_test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the extracted data\n",
    "num_plate_folder = os.path.join(extract_to, \"num plate\")\n",
    "\n",
    "if os.path.exists(num_plate_folder):\n",
    "    # List all class folders\n",
    "    class_folders = [f for f in os.listdir(num_plate_folder) \n",
    "                    if os.path.isdir(os.path.join(num_plate_folder, f))]\n",
    "    \n",
    "    print(f\"Found {len(class_folders)} classes in the dataset:\")\n",
    "    for i, folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(num_plate_folder, folder)\n",
    "        num_images = len([f for f in os.listdir(class_path) \n",
    "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\"  {i+1}. {folder}: {num_images} images\")\n",
    "else:\n",
    "    print(f\"Error: Could not find folder {num_plate_folder}\")\n",
    "    print(\"Please check the structure of your zip file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bb7df",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Now let's augment the data to increase our sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the dataset similar to the original notebook\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "num_plate_folder = os.path.join(extract_to, \"num plate\")\n",
    "\n",
    "# Process each class folder\n",
    "for class_folder in os.listdir(num_plate_folder):\n",
    "    class_path = os.path.join(num_plate_folder, class_folder)\n",
    "    aug_class_path = os.path.join(aug_data_dir, class_folder)\n",
    "    os.makedirs(aug_class_path, exist_ok=True)\n",
    "    \n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    # Copy original images\n",
    "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    for img_name in images:\n",
    "        try:\n",
    "            shutil.copy(os.path.join(class_path, img_name), os.path.join(aug_class_path, img_name))\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {img_name}: {e}\")\n",
    "    \n",
    "    # Add augmented images\n",
    "    aug_count = 0\n",
    "    img_cycle = iter(images)\n",
    "    \n",
    "    while aug_count < 100:\n",
    "        try:\n",
    "            img_name = next(img_cycle)\n",
    "        except StopIteration:\n",
    "            img_cycle = iter(images)\n",
    "            img_name = next(img_cycle)\n",
    "            \n",
    "        try:\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n",
    "            img_array = np.expand_dims(np.array(img), 0)\n",
    "            aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "            aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "            aug_pil = Image.fromarray(aug_img)\n",
    "            aug_pil.save(os.path.join(aug_class_path, f\"{img_name.split('.')[0]}_extra{aug_count}.jpg\"))\n",
    "            aug_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error augmenting {img_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Processed {class_folder}: {len(images)} original + {aug_count} augmented images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for class_folder in os.listdir(aug_data_dir):\n",
    "    class_path = os.path.join(aug_data_dir, class_folder)\n",
    "    \n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    # Get all images in this class\n",
    "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(f\"No images found for class {class_folder}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Split into train and test\n",
    "    train_imgs, test_imgs = train_test_split(images, test_size=0.05, random_state=42)\n",
    "    \n",
    "    # Create class folders in train and test directories\n",
    "    os.makedirs(os.path.join(processed_train_dir, class_folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(processed_test_dir, class_folder), exist_ok=True)\n",
    "    \n",
    "    # Copy images to respective folders\n",
    "    for img in train_imgs:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(processed_train_dir, class_folder, img))\n",
    "    \n",
    "    for img in test_imgs:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(processed_test_dir, class_folder, img))\n",
    "    \n",
    "    print(f\"{class_folder}: {len(train_imgs)} training images, {len(test_imgs)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing without plate detection (for comparison)\n",
    "def preprocess_basic_dataset(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for class_folder in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_folder)\n",
    "        save_path = os.path.join(output_dir, class_folder)\n",
    "        \n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        for img_file in os.listdir(class_path):\n",
    "            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                img = Image.open(img_path).convert(\"L\")\n",
    "                img = img.resize((128, 128))\n",
    "                img.save(os.path.join(save_path, img_file))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "# Apply basic preprocessing to create the final dataset\n",
    "preprocess_basic_dataset(processed_train_dir, final_train_dir)\n",
    "preprocess_basic_dataset(processed_test_dir, final_test_dir)\n",
    "\n",
    "print(\"Basic preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfafe3e",
   "metadata": {},
   "source": [
    "## Now Apply the Enhanced License Plate Detection\n",
    "\n",
    "With our dataset prepared, let's apply our improved license plate detection preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d35e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the datasets with license plate detection\n",
    "print(\"Starting to process train data with license plate detection...\")\n",
    "prepare_improved_dataset(processed_train_dir, improved_train_dir, detect_plates=True)\n",
    "\n",
    "print(\"\\nStarting to process test data with license plate detection...\")\n",
    "prepare_improved_dataset(processed_test_dir, improved_test_dir, detect_plates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbc11f",
   "metadata": {},
   "source": [
    "## Now Set Up the Data Generators\n",
    "\n",
    "With both basic and improved datasets ready, we can set up our data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656df32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data generators\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_gen = plate_datagen.flow_from_directory(\n",
    "    improved_train_dir,  # Use improved dataset with plate detection\n",
    "    target_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Test data generator (no augmentation needed for validation)\n",
    "test_gen = val_datagen.flow_from_directory(\n",
    "    improved_test_dir,  # Use improved dataset with plate detection\n",
    "    target_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Get class indices and number of classes\n",
    "class_indices = train_gen.class_indices\n",
    "class_labels = list(class_indices.keys())\n",
    "num_classes = len(class_indices)\n",
    "\n",
    "print(f\"Found {num_classes} classes: {class_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c02d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the improved model\n",
    "# Create the model\n",
    "improved_model = create_improved_model(input_shape=(128, 128, 1), num_classes=num_classes)\n",
    "\n",
    "# Display model summary\n",
    "improved_model.summary()\n",
    "\n",
    "# Set up callbacks\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"improved_plate_model.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = improved_model.fit(\n",
    "    train_gen,\n",
    "    epochs=50,  # Adjust as needed\n",
    "    validation_data=test_gen,\n",
    "    callbacks=[model_checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ec09e",
   "metadata": {},
   "source": [
    "## Importing Data from Original MLDEV_02 Notebook\n",
    "\n",
    "Let's load the trained model and data from the original notebook to use with our improved pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original model from MLDEV_02 notebook\n",
    "original_model_path = \"final_model.h5\"  # Path to the model trained in MLDEV_02\n",
    "\n",
    "print(f\"Loading original model from {original_model_path}...\")\n",
    "try:\n",
    "    original_model = load_model(original_model_path)\n",
    "    print(\"Original model loaded successfully!\")\n",
    "    original_model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading original model: {e}\")\n",
    "    print(\"Make sure the model file exists and is accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ae956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class mappings from original data\n",
    "try:\n",
    "    # Load original training data to get class indices\n",
    "    original_train_path = 'final/train'\n",
    "    \n",
    "    temp_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    original_data = temp_datagen.flow_from_directory(\n",
    "        original_train_path,\n",
    "        target_size=(128, 128),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=1,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    # Get original class indices and labels\n",
    "    original_class_indices = original_data.class_indices\n",
    "    original_class_labels = list(original_class_indices.keys())\n",
    "    \n",
    "    print(f\"Found {len(original_class_labels)} classes in original data:\")\n",
    "    for i, label in enumerate(original_class_labels):\n",
    "        print(f\"  {i}: {label}\")\n",
    "        \n",
    "    # Save these for later use with our improved model\n",
    "    import json\n",
    "    with open('class_labels.json', 'w') as f:\n",
    "        json.dump(original_class_labels, f)\n",
    "    print(\"Class labels saved to class_labels.json\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing original training data: {e}\")\n",
    "    print(\"Make sure the original dataset paths are correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701858ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test original model on a sample image\n",
    "def test_original_model(img_path):\n",
    "    if 'original_model' not in globals():\n",
    "        print(\"Original model not loaded. Please run the previous cell first.\")\n",
    "        return\n",
    "    \n",
    "    # Use the original preprocessing function from MLDEV_02\n",
    "    img = basic_preprocess_image(img_path)\n",
    "    \n",
    "    # Make prediction with original model\n",
    "    prediction = original_model.predict(img)\n",
    "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_class = original_class_labels[predicted_class_index]\n",
    "    confidence = prediction[0][predicted_class_index]\n",
    "    \n",
    "    # Display the image and prediction\n",
    "    img_display = Image.open(img_path)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img_display)\n",
    "    plt.title(f\"Original Model Prediction: {predicted_class} ({confidence:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Original model predicts: {predicted_class} with {confidence:.2f} confidence\")\n",
    "    return predicted_class, confidence\n",
    "\n",
    "# You can test with any image from your dataset\n",
    "# Example: test_original_model('path/to/test/image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebaa84",
   "metadata": {},
   "source": [
    "## Transfer Learning: Using the Original Model as Base\n",
    "\n",
    "We can leverage the weights from the original model as a starting point for our improved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee399325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_model(original_model, num_classes=29):\n",
    "    \"\"\"Create a transfer learning model based on the original model\"\"\"\n",
    "    # Extract layers from the original model up to the flatten layer\n",
    "    base_model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Add convolutional layers from the original model\n",
    "    for layer in original_model.layers[:-3]:  # Skip the last Dense layers\n",
    "        base_model.add(layer)\n",
    "        \n",
    "    # Freeze the base layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Create a new model with our improved architecture\n",
    "    inputs = Input(shape=(128, 128, 1))\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    # Add our improved dense layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    transfer_model = Model(inputs=inputs, outputs=outputs)\n",
    "    transfer_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return transfer_model\n",
    "\n",
    "# Create the transfer learning model\n",
    "if 'original_model' in globals():\n",
    "    transfer_model = create_transfer_model(original_model, num_classes=len(original_class_labels))\n",
    "    transfer_model.summary()\n",
    "    print(\"Transfer learning model created successfully!\")\n",
    "else:\n",
    "    print(\"Original model not loaded. Please run the previous cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2935b",
   "metadata": {},
   "source": [
    "## Upload and Extract Dataset in Google Colab\n",
    "\n",
    "First, let's make sure we can get the data from the uploaded zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb381e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab: Mount Google Drive (if needed)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted.\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab or drive already mounted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the zip file exists or prompt the user to upload it\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "zip_path = '/content/num+plate.zip'\n",
    "extract_to = 'dataset'\n",
    "\n",
    "# Check if the zip file exists\n",
    "if not os.path.exists(zip_path):\n",
    "    from google.colab import files\n",
    "    print(\"Please upload the num+plate.zip file.\")\n",
    "    uploaded = files.upload()\n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"Uploaded {filename}\")\n",
    "        if filename.endswith('.zip'):\n",
    "            # Move the uploaded file to the expected location\n",
    "            !mv \"{filename}\" \"{zip_path}\"\n",
    "\n",
    "# Now extract the zip file\n",
    "if os.path.exists(zip_path):\n",
    "    print(f\"Extracting {zip_path}...\")\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    print(f\"Extracted {zip_path} to {extract_to}/\")\n",
    "else:\n",
    "    print(f\"Error: {zip_path} not found. Please upload the zip file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the dataset structure\n",
    "num_plate_folder = os.path.join(extract_to, \"num plate\")\n",
    "\n",
    "if os.path.exists(num_plate_folder):\n",
    "    # List all class folders\n",
    "    class_folders = [f for f in os.listdir(num_plate_folder) \n",
    "                    if os.path.isdir(os.path.join(num_plate_folder, f))]\n",
    "    \n",
    "    print(f\"Found {len(class_folders)} classes in the dataset:\")\n",
    "    for i, folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(num_plate_folder, folder)\n",
    "        num_images = len([f for f in os.listdir(class_path) \n",
    "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\"  {i+1}. {folder}: {num_images} images\")\n",
    "else:\n",
    "    print(f\"Error: Could not find folder {num_plate_folder}\")\n",
    "    print(\"Please check the structure of your zip file.\")\n",
    "    print(\"The expected structure is: num+plate.zip → num plate → [class folders]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a01160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all required directories\n",
    "aug_data_dir = \"aug_data\"\n",
    "processed_train_dir = \"processed/train\"\n",
    "processed_test_dir = \"processed/test\"\n",
    "final_train_dir = \"final/train\"\n",
    "final_test_dir = \"final/test\"\n",
    "improved_train_dir = \"improved_data/train\"\n",
    "improved_test_dir = \"improved_data/test\"\n",
    "\n",
    "# Create all directories\n",
    "for directory in [aug_data_dir, processed_train_dir, processed_test_dir, \n",
    "                  final_train_dir, final_test_dir, improved_train_dir, improved_test_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490093d1",
   "metadata": {},
   "source": [
    "## Install Required Packages\n",
    "\n",
    "Make sure we have all the required packages installed in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edff8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (for Google Colab)\n",
    "!pip install -q opencv-python\n",
    "!pip install -q scikit-image\n",
    "!pip install -q imutils\n",
    "\n",
    "# Verify installations\n",
    "import cv2\n",
    "import skimage\n",
    "import imutils\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"scikit-image version: {skimage.__version__}\")\n",
    "print(f\"imutils version: {imutils.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327b446",
   "metadata": {},
   "source": [
    "## Export the Model for Android App\n",
    "\n",
    "Let's convert our trained model to TensorFlow Lite format for use in our Android app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TFLite for Android\n",
    "try:\n",
    "    if 'improved_model' in globals():\n",
    "        # Convert model to TFLite format\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(improved_model)\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        # Save the TFLite model\n",
    "        tflite_path = \"android_model.tflite\"\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        print(f\"Model converted and saved to {tflite_path}\")\n",
    "        print(f\"Model size: {os.path.getsize(tflite_path) / (1024 * 1024):.2f} MB\")\n",
    "        \n",
    "        # Save class labels\n",
    "        label_path = \"android_labels.txt\"\n",
    "        with open(label_path, 'w') as f:\n",
    "            for label in class_labels:\n",
    "                f.write(f\"{label}\\n\")\n",
    "        \n",
    "        print(f\"Class labels saved to {label_path}\")\n",
    "        \n",
    "        # Download files to local machine\n",
    "        from google.colab import files\n",
    "        files.download(tflite_path)\n",
    "        files.download(label_path)\n",
    "    else:\n",
    "        print(\"Model not found. Please train the model first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error converting model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
